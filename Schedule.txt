目标： 做长文本作家文体风格分析
输入文章，输出可能的作家
（一大堆引用）

效果；（编码器）编码一个作家的风格；能够对新文本做分类，根据距离度量判断最相似的作家


应用：作品风格借鉴和相似度检测、文学风格研究、文本作者身份识别（鲁迅为例）
“你的文章风格像谁？”

1. 数据清洗
用notepad++ convert to utf-8再用python读入
用notepad清洗了广告...
Python数据清洗完成（包括清洗广告和章节开头）
注释和无关章节需要人工处理

2. 特征提取
先分句――找句号、叹号、问号、冒号、分号、省略号切开，插入\n

再分词――FudanNLP貌似效果不好，考虑jieba

词汇特征：
jieba关键词提取（基于TFIDF）――与主题相关，不能用
词汇丰富度
标注词性后使用词频，可以求出各个词性的前几个最高频词
词性特征：
	词性标注使用jieba

标点特征：各种标点出现次数

句法特征：
	虚词（功能词）包括介词p、（并列、从属）连词c、叹词e、结构助词u、语气词y、方位词f

依存句法特征：FudanNLP 输入一个句子，输出依赖树，包括22种依赖关系和若干种（42）词性
完成
用每一句的依赖关系代表这一句的结构

语义特征：与主题相关，不能用

复合特征：
各种东西除一下

3. 分类：作者识别
大样本建立作家风格数据库（随时可以运行）
降维？
新样本测试准确率
设计比对算法：加权距离度量
数据可视化――句法依存的概率分布图、词云、直方图等等（完成）
规范储存方式，每行一个数据（完成）
把数值转为概率

_始蟾妫。。
把报告写好再优化

4. 问题与改善
怎样优化特征提取？
1. 增大句法依存特征的权重，减小词汇特征的权重, feature_importance检验
2。用每一篇独立的同作者文章编码作为标记数据，然后训练分类器
3. 怎样充分利用句法依存的信息？RNN？用RNN学习句法依存序列
需要用RNN处理句法依存的序列信息，学习出作家的文法规律
训练RNN

论文neural machine translation? 用神经网络和云计算




将特征提取和数据预处理分离（已完成）

怎么调java是个大问题？（已解决）
考虑到没必要多次重启python解析器，应该用Python来循环读取文件，然后batch调用。（已优化）


怎样利用段落特征？
怎样利用句间特征？


baidu api调用：当且仅当text的值为GBK时有回应，但是回应的是GBK编码串的答案。。。